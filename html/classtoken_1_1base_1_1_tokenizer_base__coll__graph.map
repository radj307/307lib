<map id="token::base::TokenizerBase&lt; LexemeT, Dictionary, TokenType, Token &gt;" name="token::base::TokenizerBase&lt; LexemeT, Dictionary, TokenType, Token &gt;">
<area shape="rect" id="node1" title="Base TokenizerBase object that accepts a stringstream and lexeme dictionary, then tokenizes the data...." alt="" coords="101,519,352,575"/>
<area shape="rect" id="node2" title=" " alt="" coords="92,429,225,456"/>
<area shape="rect" id="node3" title=" " alt="" coords="71,339,246,380"/>
<area shape="rect" id="node4" title=" " alt="" coords="84,248,233,289"/>
<area shape="rect" id="node5" title=" " alt="" coords="5,157,147,199"/>
<area shape="rect" id="node6" title=" " alt="" coords="73,81,244,108"/>
<area shape="rect" id="node8" title=" " alt="" coords="171,157,317,199"/>
<area shape="rect" id="node7" title=" " alt="" coords="105,5,212,32"/>
<area shape="rect" id="node9" title=" " alt="" coords="250,429,339,456"/>
</map>
